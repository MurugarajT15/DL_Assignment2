# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CauD7nfwC07F10mnSJr1XBft6uVpl0VT
"""



import argparse
import torch
import torch.nn as nn
import torch.optim as optim

from models.cnn import Convolutional_Neural_Network
from data.transforms import get_datasets

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch_size", type=int, default=64)
    parser.add_argument("--num_filters", type=int, default=32)
    parser.add_argument("--filter_org", type=str, choices=["same", "half","double"], default="half")
    parser.add_argument("--kernel_size", type=int, nargs=5, default=[3,3,3,3,3])
    parser.add_argument("--act_fn", type=str, choices=["relu", "gelu","silu","mish","tanh"], default="gelu")
    parser.add_argument("--num_neurons", type=int, default=128)
    parser.add_argument("--batch_norm", action="store_true")
    parser.add_argument("--dropout_rate", type=float, default=0.0)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--epochs", type=int, default=2)
    parser.add_argument("--data_dir", type=str, default="./data/inaturalist_12k/train")
    return parser.parse_args()

def train(config):
    trainset, valset = get_datasets(config.data_dir)

    model = Convolutional_Neural_Network(
        trainset, valset,
        batch_size=config.batch_size,
        num_filters=config.num_filters,
        filter_org=config.filter_org,
        kernel_size=config.kernel_size,
        act_fn=config.act_fn,
        num_neurons=config.num_neurons,
        batch_norm=config.batch_norm,
        dropout_rate=config.dropout_rate
    )

    loss_fn = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config.lr)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(config.epochs):
        model.train()
        total_loss, total_correct = 0, 0
        for images, labels in model.dataloader_train:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            total_correct += (outputs.argmax(1) == labels).sum().item()
        train_accuracy = total_correct / len(trainset) * 100
        print(f"Epoch [{epoch+1}/{config.epochs}] Train Loss: {total_loss:.4f} | train Accuracy: {train_accuracy:.2f}")

        model.eval()
        val_correct,total_val_loss = 0,0
        with torch.no_grad():
            for images, labels in model.dataloader_val:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                val_correct += (outputs.argmax(1) == labels).sum().item()
                val_loss=loss_fn(outputs, labels)
                total_val_loss+=val_loss.item()
        val_accuracy = val_correct / len(valset) * 100
        print(f"Epoch [{epoch+1}/{config.epochs}] Validation Loss: {total_val_loss:.4f} | Validation Accuracy: {val_accuracy:.2f}*{100}")

if __name__ == "__main__":
    args = parse_args()
    train(args)

