{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11369159,"sourceType":"datasetVersion","datasetId":7116973}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:02:57.924530Z","iopub.execute_input":"2025-04-20T16:02:57.925042Z","iopub.status.idle":"2025-04-20T16:03:00.842808Z","shell.execute_reply.started":"2025-04-20T16:02:57.925015Z","shell.execute_reply":"2025-04-20T16:03:00.841994Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torch.utils.data import random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:11.471826Z","iopub.execute_input":"2025-04-20T16:03:11.472415Z","iopub.status.idle":"2025-04-20T16:03:11.477569Z","shell.execute_reply.started":"2025-04-20T16:03:11.472390Z","shell.execute_reply":"2025-04-20T16:03:11.476820Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"13b86763ab8ddf529c91c7dce385c6cb04b5253e\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:13.721232Z","iopub.execute_input":"2025-04-20T16:03:13.721891Z","iopub.status.idle":"2025-04-20T16:03:13.853533Z","shell.execute_reply.started":"2025-04-20T16:03:13.721838Z","shell.execute_reply":"2025-04-20T16:03:13.852831Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m015\u001b[0m (\u001b[33miitm-ma23m015\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from torchvision import transforms, datasets\ntrain_set = \"/kaggle/input/inature12k/inaturalist_12K/train\"\ntest_set = \"/kaggle/input/inature12k/inaturalist_12K/val\"\nIMG_SIZE = (224,224)\n# Transformations to apply to the images\ntransform = transforms.Compose([\n    transforms.Resize(IMG_SIZE),  # Resize the images\n    transforms.ToTensor(),        \n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])  # Normalize the images\n\n\n# Use ImageFolder to create a dataset\ntrainset = datasets.ImageFolder(root=train_set, transform=transform)\nval_size = int(0.2 * len(trainset))\ntrain_size = len(trainset) - val_size\ntrainset, valset = random_split(trainset, [train_size, val_size])\ntestset = datasets.ImageFolder(root=test_set, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:16.872443Z","iopub.execute_input":"2025-04-20T16:03:16.872720Z","iopub.status.idle":"2025-04-20T16:03:24.873834Z","shell.execute_reply.started":"2025-04-20T16:03:16.872699Z","shell.execute_reply":"2025-04-20T16:03:24.873265Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nimport wandb\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass pretrainedCNN():\n    def __init__(self, trainset, valset, model, batch_size=32, freeze_percent=1):\n        self.model = model\n\n        # Freeze layers based on freeze_percent\n        layers = list(self.model.parameters())\n        num_layers_to_freeze = int(freeze_percent * len(layers))\n\n        for i, param in enumerate(layers):\n            param.requires_grad = False if i < num_layers_to_freeze else True\n\n        # Replace the final FC layer\n        num_classes = 10  \n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, num_classes)\n        self.model.fc.to(device)\n\n      \n        self.dataloader_train = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n        self.dataloader_val = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n\n    def train(self, epochs=10, lr=0.001, weight_decay=0):\n        self.model.to(device)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()),\n                               lr=lr, weight_decay=weight_decay)\n\n        for epoch in range(1, epochs + 1):\n            self.model.train()\n            train_accuracy, train_loss = 0, 0\n            total_train = 0\n\n            for inputs, labels in self.dataloader_train:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = self.model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n                train_loss += loss.item() * inputs.size(0)\n                train_accuracy += (outputs.argmax(1) == labels).sum().item()\n                total_train += labels.size(0)\n\n            train_acc = train_accuracy / total_train\n            wandb.log({'epoch': epoch, 'train_accuracy': train_acc * 100})\n\n            # Validation\n            self.model.eval()\n            val_accuracy, val_loss = 0, 0\n            total_val = 0\n\n            with torch.no_grad():\n                for inputs, labels in self.dataloader_val:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    outputs = self.model(inputs)\n                    loss = criterion(outputs, labels)\n\n                    val_loss += loss.item() * inputs.size(0)\n                    val_accuracy += (outputs.argmax(1) == labels).sum().item()\n                    total_val += labels.size(0)\n\n            val_acc = val_accuracy / total_val\n            avg_val_loss = val_loss / total_val\n\n            print(f\"Epoch {epoch}: Train Acc: {train_acc*100:.2f}%  Val Acc: {val_acc*100:.2f}%\")\n            wandb.log({'epoch': epoch,\n                       'validation_accuracy': val_acc * 100,\n                       'validation_loss': avg_val_loss})\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:28.941331Z","iopub.execute_input":"2025-04-20T16:03:28.941813Z","iopub.status.idle":"2025-04-20T16:03:28.952070Z","shell.execute_reply.started":"2025-04-20T16:03:28.941791Z","shell.execute_reply":"2025-04-20T16:03:28.951288Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Sweep config\nsweep_config = {\n    'method': 'bayes',\n    'name': 'Pretuning sweep',\n    'metric': {'goal': 'maximize', 'name': 'validation_accuracy'},\n    'parameters': {\n        'learning_rate': {'values': [1e-3, 1e-4]},\n        'freeze_percent': {'values': [0.2, 0.6, 0.8, 0.9]},\n        'L2_regularisation': {'values': [0, 0.0005, 0.05]},\n        'batch_size': {'values': [32, 64]},\n        'epochs': {'values': [10, 15]}\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:31.916161Z","iopub.execute_input":"2025-04-20T16:03:31.916959Z","iopub.status.idle":"2025-04-20T16:03:31.921087Z","shell.execute_reply.started":"2025-04-20T16:03:31.916926Z","shell.execute_reply":"2025-04-20T16:03:31.920413Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep = sweep_config, project='DA6401-Assignment_2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:35.284169Z","iopub.execute_input":"2025-04-20T16:03:35.284429Z","iopub.status.idle":"2025-04-20T16:03:35.584773Z","shell.execute_reply.started":"2025-04-20T16:03:35.284408Z","shell.execute_reply":"2025-04-20T16:03:35.584213Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: qzj8r57u\nSweep URL: https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def main():\n    with wandb.init() as run:\n        config = wandb.config\n        wandb.run.name = f\"-bs_{config.batch_size}-ep_{config.epochs}-lr_{config.learning_rate}-freeze_{config.freeze_percent}\"\n\n        model = models.resnet50(pretrained=True)\n        cnn_model = pretrainedCNN(trainset, valset, model,\n                                  batch_size=config.batch_size,\n                                  freeze_percent=config.freeze_percent)\n        cnn_model.train(epochs=config.epochs,\n                        lr=config.learning_rate,\n                        weight_decay=config.L2_regularisation)\n\nwandb.agent(sweep_id, function=main, count=2)\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:03:37.765987Z","iopub.execute_input":"2025-04-20T16:03:37.766228Z","iopub.status.idle":"2025-04-20T16:42:47.903484Z","shell.execute_reply.started":"2025-04-20T16:03:37.766212Z","shell.execute_reply":"2025-04-20T16:42:47.902723Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wsn0tqp3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tL2_regularisation: 0.05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_percent: 0.6\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250420_160343-wsn0tqp3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/wsn0tqp3' target=\"_blank\">rich-sweep-1</a></strong> to <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/wsn0tqp3' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/wsn0tqp3</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 204MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 68.23% /n Val Acc: 69.88%\nEpoch 2: Train Acc: 76.14% /n Val Acc: 62.58%\nEpoch 3: Train Acc: 78.49% /n Val Acc: 67.33%\nEpoch 4: Train Acc: 80.21% /n Val Acc: 67.83%\nEpoch 5: Train Acc: 83.09% /n Val Acc: 69.43%\nEpoch 6: Train Acc: 84.36% /n Val Acc: 66.68%\nEpoch 7: Train Acc: 86.33% /n Val Acc: 62.98%\nEpoch 8: Train Acc: 87.85% /n Val Acc: 68.93%\nEpoch 9: Train Acc: 89.58% /n Val Acc: 68.43%\nEpoch 10: Train Acc: 90.48% /n Val Acc: 66.73%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>validation_accuracy</td><td>█▁▆▆█▅▁▇▇▅</td></tr><tr><td>validation_loss</td><td>▁█▅▄▂▆█▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>90.475</td></tr><tr><td>validation_accuracy</td><td>66.73337</td></tr><tr><td>validation_loss</td><td>1.12097</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">-bs_32-ep_10-lr_0.0001-freeze_0.6</strong> at: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/wsn0tqp3' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/wsn0tqp3</a><br> View project at: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250420_160343-wsn0tqp3/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p1ah1m7h with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tL2_regularisation: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_percent: 0.6\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250420_162659-p1ah1m7h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/p1ah1m7h' target=\"_blank\">summer-sweep-2</a></strong> to <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/sweeps/qzj8r57u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/p1ah1m7h' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/p1ah1m7h</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1: Train Acc: 70.17% /n Val Acc: 76.09%\nEpoch 2: Train Acc: 88.64% /n Val Acc: 77.79%\nEpoch 3: Train Acc: 95.14% /n Val Acc: 77.44%\nEpoch 4: Train Acc: 96.89% /n Val Acc: 77.84%\nEpoch 5: Train Acc: 98.02% /n Val Acc: 77.09%\nEpoch 6: Train Acc: 98.00% /n Val Acc: 74.54%\nEpoch 7: Train Acc: 97.69% /n Val Acc: 75.09%\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▆▇████</td></tr><tr><td>validation_accuracy</td><td>▄█▇█▆▁▂</td></tr><tr><td>validation_loss</td><td>▁▁▃▃▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>97.6875</td></tr><tr><td>validation_accuracy</td><td>75.08754</td></tr><tr><td>validation_loss</td><td>1.05729</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">-bs_32-ep_15-lr_0.0001-freeze_0.6</strong> at: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/p1ah1m7h' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2/runs/p1ah1m7h</a><br> View project at: <a href='https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2' target=\"_blank\">https://wandb.ai/iitm-ma23m015/DA6401-Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250420_162659-p1ah1m7h/logs</code>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}